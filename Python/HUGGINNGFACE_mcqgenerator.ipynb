{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# MCQ Generator with LangChain and Hugging Face\n",
    "\n",
    "This notebook demonstrates how to build a Multiple Choice Question (MCQ) generator using LangChain and a model from the Hugging Face Hub. The goal of this project is to automatically generate a quiz from a given text, and then evaluate the generated quiz for quality and relevance.\n",
    "\n",
    "This project is a great way to showcase skills in:\n",
    "\n",
    "*   **Natural Language Processing (NLP):** Using large language models (LLMs) to understand and process text.\n",
    "*   **LangChain:** Building complex applications with LLMs by chaining together different components.\n",
    "*   **API Integration:** Interacting with the Hugging Face Hub to leverage a wide range of open-source models.\n",
    "*   **Prompt Engineering:** Designing effective prompts to guide the LLM's output.\n",
    "*   **Python and Jupyter Notebooks:** Writing clean, well-documented code to solve a real-world problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f6g7h8i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.75 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-google-genai) (0.3.76)\n",
      "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-google-genai) (2.11.9)\n",
      "Collecting filetype<2,>=1.2 (from langchain-google-genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.32.1)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.32.5)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading grpcio-1.75.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2025.8.3)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-core>=0.3.75->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/gen-ai-portfolio/.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
      "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.75.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.75.0-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: filetype, pyasn1, proto-plus, grpcio, googleapis-common-protos, cachetools, rsa, pyasn1-modules, grpcio-status, google-auth, google-api-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\u001b[2K  Attempting uninstall: cachetools\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: cachetools 6.2.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling cachetools-6.2.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled cachetools-6.2.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [langchain-google-genai]e-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-5.5.2 filetype-1.2.0 google-ai-generativelanguage-0.7.0 google-api-core-2.25.1 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.75.0 grpcio-status-1.75.0 langchain-google-genai-2.1.12 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75d3ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration\n",
    "\n",
    "Next, we'll load the Hugging Face API key from a `.env` file. This is a good practice for managing sensitive information like API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98459676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e7db780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your Hugging Face API Key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6g7",
   "metadata": {},
   "source": [
    "## 3. LangChain Setup\n",
    "\n",
    "Now we'll set up the core components of our LangChain application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_markdown_cell_for_gemma",
   "metadata": {},
   "source": [
    "### 3.1. IMPORTANT: Accept Gemma's License Terms\n",
    "\n",
    "Before using the `google/gemma-7b` model, you **must** visit its page on the Hugging Face Hub and accept the license terms. If you fail to do this, the API call will not work.\n",
    "\n",
    "[Click here to go to the `google/gemma-7b` model page](https://huggingface.co/google/gemma-7b) and accept the terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "### 3.2. Initialize the Language Model\n",
    "\n",
    "We'll use the `google/gemma-7b` model from the Hugging Face Hub. It is a powerful text-generation model from Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a7b6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "173fa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=repo_id,\n",
    "#     huggingfacehub_api_token=HUGGINGFACE_API_KEY,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     temperature=0.5\n",
    "# )\n",
    "\n",
    "# Initialize the Gemini-Pro model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6g7h8i9",
   "metadata": {},
   "source": [
    "### 3.3. Define Prompt Templates\n",
    "\n",
    "We need two prompt templates: one for generating the MCQs and another for evaluating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c37b6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7127748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = '''\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g7h8i9j0",
   "metadata": {},
   "source": [
    "### 3.4. Create LangChain Chains\n",
    "\n",
    "We'll create two `LLMChain` instances: one for quiz generation and one for evaluation. Then, we'll combine them into a `SequentialChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56a0ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13616b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75a2df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "480c9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02dbfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8i9j0k1",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "Now we'll load the text from the `data.txt` file. This text will be used as the source material for generating the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12bcfa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8bd8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "## 5. MCQ Generation and Evaluation\n",
    "\n",
    "Now it's time to run our chain and generate the MCQs. We'll specify the number of questions, the subject, and the tone of the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87f72cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 5\n",
    "SUBJECT = \"biology\"\n",
    "TONE = \"simple\"\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b12c0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text: Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\n",
      "\n",
      "Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\n",
      "\n",
      "Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to \n",
      "create a quiz of 5 multiple choice questions for biology students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
      "Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for biology students.\n",
      "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,\n",
      "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "```json\n",
      "{\n",
      "  \"1\": {\n",
      "    \"mcq\": \"What is biology?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"The study of rocks and minerals\",\n",
      "      \"b\": \"The study of the Earth's atmosphere\",\n",
      "      \"c\": \"The scientific study of life\",\n",
      "      \"d\": \"The study of human behavior\"\n",
      "    },\n",
      "    \"correct\": \"c\"\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"mcq\": \"Which of the following is NOT a unifying theme in biology?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"All organisms are made of cells\",\n",
      "      \"b\": \"Hereditary information is encoded in genes\",\n",
      "      \"c\": \"Organisms are unaffected by their environment\",\n",
      "      \"d\": \"Evolution explains the unity and diversity of life\"\n",
      "    },\n",
      "    \"correct\": \"c\"\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"mcq\": \"What is a major process that allows organisms to grow and reproduce?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"Photosynthesis only\",\n",
      "      \"b\": \"Energy processing\",\n",
      "      \"c\": \"Cellular respiration only\",\n",
      "      \"d\": \"Water absorption only\"\n",
      "    },\n",
      "    \"correct\": \"b\"\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"mcq\": \"What is the approximate age of the oldest life forms on Earth, according to the text?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"1 billion years\",\n",
      "      \"b\": \"2.7 billion years\",\n",
      "      \"c\": \"3.7 billion years\",\n",
      "      \"d\": \"5 billion years\"\n",
      "    },\n",
      "    \"correct\": \"c\"\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"mcq\": \"Which of the following is an example of a eukaryotic organism?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"Archaea\",\n",
      "      \"b\": \"Bacteria\",\n",
      "      \"c\": \"Plants\",\n",
      "      \"d\": \"All of the above are prokaryotes\"\n",
      "    },\n",
      "    \"correct\": \"c\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have accepted the license for the model on Hugging Face Hub\n",
    "response = generate_evaluate_chain.invoke(\n",
    "    {\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j0k1l2m3",
   "metadata": {},
   "source": [
    "### 5.1. Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2354f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RAW MODEL OUTPUT FOR 'quiz' ---\n",
      "'```json\\n{\\n  \"1\": {\\n    \"mcq\": \"What is biology?\",\\n    \"options\": {\\n      \"a\": \"The study of rocks and minerals\",\\n      \"b\": \"The study of the Earth\\'s atmosphere\",\\n      \"c\": \"The scientific study of life\",\\n      \"d\": \"The study of human behavior\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"2\": {\\n    \"mcq\": \"Which of the following is NOT a unifying theme in biology?\",\\n    \"options\": {\\n      \"a\": \"All organisms are made of cells\",\\n      \"b\": \"Hereditary information is encoded in genes\",\\n      \"c\": \"Organisms are unaffected by their environment\",\\n      \"d\": \"Evolution explains the unity and diversity of life\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"3\": {\\n    \"mcq\": \"What is a major process that allows organisms to grow and reproduce?\",\\n    \"options\": {\\n      \"a\": \"Photosynthesis only\",\\n      \"b\": \"Energy processing\",\\n      \"c\": \"Cellular respiration only\",\\n      \"d\": \"Water absorption only\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"4\": {\\n    \"mcq\": \"What is the approximate age of the oldest life forms on Earth, according to the text?\",\\n    \"options\": {\\n      \"a\": \"1 billion years\",\\n      \"b\": \"2.7 billion years\",\\n      \"c\": \"3.7 billion years\",\\n      \"d\": \"5 billion years\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"5\": {\\n    \"mcq\": \"Which of the following is an example of a eukaryotic organism?\",\\n    \"options\": {\\n      \"a\": \"Archaea\",\\n      \"b\": \"Bacteria\",\\n      \"c\": \"Plants\",\\n      \"d\": \"All of the above are prokaryotes\"\\n    },\\n    \"correct\": \"c\"\\n  }\\n}\\n```'\n",
      "--- END OF RAW OUTPUT ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- RAW MODEL OUTPUT FOR 'quiz' ---\")\n",
    "print(repr(response['quiz']))\n",
    "print(\"--- END OF RAW OUTPUT ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k1l2m3n4",
   "metadata": {},
   "source": [
    "## 6. Output Processing\n",
    "\n",
    "Finally, we'll process the output from the LangChain pipeline. We'll parse the generated quiz, format it as a Pandas DataFrame, and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9051c75c",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m quiz = response.get(\u001b[33m\"\u001b[39m\u001b[33mquiz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m quiz = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquiz\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "quiz = response.get(\"quiz\")\n",
    "quiz = json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fcbb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "        ]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7fe482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4649521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df.to_csv(\"mcqgenerated_biology_quiz.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
